{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdf15d74",
   "metadata": {},
   "source": [
    "###  What is data engineering?\n",
    "1. What is data engineering?\n",
    "Hi. My name is Vincent. I'm a Data and Software Engineer at DataCamp. If you've ever heard of data science, there's a good chance you've heard of data engineering as well. This course will help you take your first steps in the world of data engineering. All very exciting, so let's get started!.\n",
    "2. What to expect\n",
    "In the first chapter, we'll start off by introducing the concept of data engineering. In the second chapter, you'll learn more about the tools data engineers use. The third chapter is all about Extracting, Transforming and Loading data, or ETL. Finally, you'll get to have a peek behind the curtain in the case study on data engineering at DataCamp. But first, let's understand what data engineers do!\n",
    "3. In comes the data engineer\n",
    "Imagine this: you've been hired as a data scientist at a young startup. Tasked with predicting customer churn, you want to use a fancy machine learning technique that you have been honing for years. However, after a bit of digging around, you realize all of your data is scattered around many databases. Additionally, the data resides in tables that are optimized for applications to run, not for analyses. To make matters worse, some legacy code has caused a lot of the data to be corrupt. In your previous company, you never really had this problem, because all the data was available to you in an orderly fashion. You're getting desperate. In comes the data engineer to the rescue.\n",
    "4. Data engineers: making your life easier\n",
    "It is the data engineer's task to make your life as a data scientist easier. Do you need data that currently comes from several different sources? No problem, the data engineer extracts data from these sources and loads it into one single database ready to use. At the same time, they've optimized the database scheme so it becomes faster to query. They also removed corrupt data. In this sense, the data engineer is one of the most valuable people in a data-driven company that wants to scale up.\n",
    "5. Definition of the job\n",
    "Back in 2015, DataCamp published an infographic on precisely this: who does what in the data science industry. In this infographic, we described a data engineer as \"an engineer that develops, constructs, tests, and maintains architectures such as databases and large-scale processing systems.\" A lot has changed since then, but the definition still holds up. The data engineer is focused on processing and handling massive amounts of data, and setting up clusters of machines to do the computing.\n",
    "6. Data Engineer vs Data Scientist\n",
    "Typically, the tasks of a data engineer consist of developing a scalable data architecture, streamlining data acquisition, setting up processes that bring data together from several sources and safeguarding data quality by cleaning up corrupt data. Typically, the data engineer also has a deep understanding of cloud technology. They generally are experienced using cloud service providers like AWS, Azure, or Google Cloud. Compare this with the tasks of a data scientist, who spend their time mining for patterns in data, applying statistical models on large datasets, building predictive models using machine learning, developing tools to monitor essential business processes, or cleaning data by removing statistical outliers. Data scientist typically have a deep understanding of the business itself.\n",
    "7. Let's practice!\n",
    "Let's see if you can recognize the qualities of a data engineer in the exercises.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04410a92",
   "metadata": {},
   "source": [
    "### Tools of the data engineer\n",
    "1. Tools of the data engineer\n",
    "Hello again. Great job on the exercises! You should now have a good understanding of what it means to be a data engineer. The data engineer moves data from several sources, processes or cleans it and finally loads it into an analytical database. They do this using several tools. This video acts as an overview to get a feeling for how data engineers fulfill their tasks using these tools. We'll spend some more time to go into the details in the second chapter.\n",
    "2. Databases\n",
    "First, data engineers are expert users of database systems. Roughly speaking, a database is a computer system that holds large amounts of data. You might have heard of SQL or NoSQL databases. If not, there are some excellent courses on DataCamp on these subjects. Often, applications rely on databases to provide certain functionality. For example, in an online store, a database holds product data like prices or amount in stock. On the other hand, other databases hold data specifically for analyses. You'll find out more about the difference in later chapters. For now, it's essential to understand that the data engineer's task begins and ends at databases.\n",
    "3. Processing\n",
    "Second, data engineers use tools that can help them quickly process data. Processing data might be necessary to clean or aggregate data or to join it together from different sources. Typically, huge amounts of data have to be processed. That is where parallel processing comes into play. Instead of processing the data on one computer, data engineers use clusters of machines to process the data. Often, these tools make an abstraction of the underlying architecture and have a simple API.\n",
    "4. Processing: an example\n",
    "For example, have a look at this code. It looks a lot like simple pandas filter or count operations. However, behind the curtains, a cluster of computers could be performing these operations using the PySpark framework. We'll get into the details of different parallel processing frameworks later, but a good data engineer understands these abstractions and knows their limitations.\n",
    "5. Scheduling\n",
    "Third, scheduling tools help to make sure data moves from one place to another at the correct time, with a specific interval. Data engineers make sure these jobs run in a timely fashion and that they run in the right order. Sometimes processing jobs need to run in a particular order to function correctly. For example, tables from two databases might need to be joined together after they are both cleaned. In the following diagram, the JoinProductOrder job needs to run after CleanProduct and CleanOrder ran.\n",
    "6. Existing tools\n",
    "Luckily all of these tools are so common that there is a lot of choice in deciding which ones to use. In this slide, I'll present a few examples of each kind of tool. Please keep in mind this list is not exhaustive, and that some companies might choose to build their own tools in-house. Two examples of databases are MySQL or PostgreSQL. An example processing tool is Spark or Hive. Finally, for scheduling, we can use Apache Airflow, Oozie, or we can use the simple bash tool: cron.\n",
    "7. A data pipeline\n",
    "To sum everything up, you can think of the data engineering pipeline through this diagram. It extracts all data through connections with several databases, transforms it using a cluster computing framework like Spark, and loads it into an analytical database. Also, everything is scheduled to run in a specific order through a scheduling framework like Airflow. A small side note here is that the sources can be external APIs or other file formats too. We'll see this in the exercises.\n",
    "8. Let's practice!\n",
    "Enough talking, let's do some exercises!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f249a6",
   "metadata": {},
   "source": [
    "### Cloud providers\n",
    "1. Cloud providers\n",
    "Hello again. Excellent work on the exercises! In this last video of this chapter, we're going to talk about cloud computing. You've probably already heard people use this term before. Data engineers are heavy users of the cloud. In this video, we'll explain why.\n",
    "2. Data processing in the cloud\n",
    "Let's take data processing as an example. You've seen in the previous video that data processing often runs on clusters of machines. In the past, companies that relied on data processing owned their own data center. You can imagine racks of servers, ready to be used. The electrical bill and maintenance were also at the company's cost. Moreover, companies needed to be able to provide enough processing power for peak moments. That also meant that at quieter times, much of the processing power remained unused. It's this waste of resources that made cloud computing so appealing. In the cloud, you use the resources you need, at the time you need them. You can see that once these cloud services came to be, many companies moved to the cloud as a way of cost optimization.\n",
    "3. Data storage in the cloud\n",
    "Apart from the costs of maintaining data centers, another reason for using cloud computing is database reliability. If you run a data-critical company, you have to prepare for the worst. Don't ask yourself the question \"will disaster strike?\" but rather ask yourself \"when will disaster strike?\" For example, a fire can break out in your data center. To be safe, you need to replicate your data at a different geographical location. That brings along a bunch of logistical problems of its own. Out of these needs, companies specializing in these kinds of issues were born. We call these companies \"cloud service providers\" now.\n",
    "4. The big three: AWS, Azure and Google\n",
    "In this slide, we'll talk about three big players in the cloud provider market. First and foremost, there's Amazon Web Services or AWS. Think about the last few websites you visited. Chances are AWS hosts at least a few of them. Back in 2017, AWS had an outage, it reportedly 'broke' the internet. That's how big AWS is. While AWS took up 32% of the market share in 2018, Microsoft Azure is the second big player and took 17% of the market. The third big player, is Google Cloud, and held 10% of the market in 2018. So we talked about the big players. However, what do they provide? We'll discuss three types of services these companies offer: Storage, Computation, and Databases.\n",
    "5. Storage\n",
    "First, storage services allow you to upload files of all types to the cloud. In an online store for example, you could upload your product images to a storage service. Storage services are typically very cheap since they don't provide much functionality other than storing the files reliably. AWS hosts S3 as a storage service. Azure has Blob Storage, and Google has Cloud Storage.\n",
    "6. Computation\n",
    "Second, computation services allow you to perform computations on the cloud. Usually, you can start up a virtual machine and use it as you wish. It's often used to host web servers, for example. Computation services are usually flexible, and you can start or stop virtual machines as needed. AWS has EC2 as a computation service, Azure has Virtual Machines, and Google has Compute Engine.\n",
    "7. Databases\n",
    "Last but not least, cloud providers host databases. We already talked about databases in the previous video, so you know what they are. For SQL databases, AWS has RDS. Azure has SQL Database, and Google has Cloud SQL.\n",
    "8. Let's practice!\n",
    "That's it for this video, good luck with the exercises.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eea76f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
